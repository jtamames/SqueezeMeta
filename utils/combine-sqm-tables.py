#!/usr/bin/python3

"""
Part of the SqueezeMeta distribution. 06/08/2019 Original version,
                            (c) Fernando Puente-Sánchez, CNB-CSIC.

Combine tabular outputs (as generated by sqm2tables.py from different
 SqueezeMeta projects.

This script can combine the results of different samples ran using the 
 sequential mode, in which each sample is run separately, and also the
 results of different coassembly or merged SqueezeMeta runs.


USAGE:
usage: combine-sqm-tables.py [-h] PROJECT_PATHS
                             [-f PATHS_FILE]
                             [-o OUTPUT_DIR] [-p OUTPUT_PREFIX]
                             [--trusted-functions] [--ignore-unclassified]
                             [--sqm-reads] [--force-overwrite]
                             project_paths [project_paths ...]

OPTIONS:
    -o/--output-dir: Name of the output directory
    -p/--output-prefix: Prefix for the output files
    --trusted-functions: Include only ORFs with highly trusted KEGG and
        COG assignments in aggregated functional tables
    --ignore-unclassified: Ignore ORFs without assigned functions in
        TPM calculation. Ignored if --sqm-reads is provided.
    --sqmreads: Projects were generated using sqm_reads.pl
    --force-overwrite: Write results even if the output directory
        already exists.
"""

from os.path import abspath, dirname, realpath
from os import mkdir
from os.path import isfile, isdir
from sys import exit
import argparse
from subprocess import call

from pandas import DataFrame

from sys import path
utils_home = abspath(dirname(realpath(__file__)))
SQMpath = abspath('{}/../'.format(utils_home))


def main(args):

    ### Check arguments.
    if args.paths_file:
        if args.project_paths:
            print('Project paths were provided directly as arguments and also in a file.')
            print('Using project paths in the file: "{}"'.format(args.paths_file))
        projPaths = [line.strip() for line in open(args.paths_file)]
    elif args.project_paths:
        projPaths = args.project_paths
    else:
        print('Project paths were not provided. Exiting...')
        exit(1)

    ### Create output dir.
    try:
       mkdir(args.output_dir)
    except OSError as e:
        if e.errno != 17:
            raise
        elif args.force_overwrite:
            pass
        else:
            print('\nThe directory {} already exists. Please remove it or use a different output name.\n'.format(args.output_dir))
            exit(1)

    ### Define stuff and things (Carl).
    sampleNames = []

    all_superkingdom = {}
    all_phylum = {}
    all_class = {}
    all_order = {}
    all_family = {}
    all_genus = {}
    all_species = {}

    prok_superkingdom = {}
    prok_phylum = {}
    prok_class = {}
    prok_order = {}
    prok_family = {}
    prok_genus = {}
    prok_species = {}

    KOabund = {}
    KOcopy = {}
    KOtpm = {}

    COGabund = {}
    COGcopy = {}
    COGtpm = {}

    PFAMabund = {}
    PFAMcopy = {}
    PFAMtpm = {}

    for projPath in projPaths:
        projName = projPath.strip('/').split('/')[-1]
        ### Validate projects.
        if not args.sqmreads:
            ok = isfile('{}/SqueezeMeta_conf.pl'.format(projPath))
        else:
            ok = isfile('{}/{}.out.mappingstat'.format(projPath, projName))
        if not ok:
            raise Exception('Path "{}" does not exist, or does not contain a valid SQM project'.format(projPath))

        ### Create tables if needed.
        if not isfile('{}/results/tables/{}.COG.abund.tsv'.format(projPath, projName)):
            print('Creating tables for project {}'.format(projName))
            if args.sqmreads and not isdir('{}/results'.format(projPath)):
                mkdir('{}/results'.format(projPath))
            if not args.sqmreads:
                command = ['{}/utils/sqm2tables.py'.format(SQMpath), '{}'.format(projpath), '{}/results/tables'.format(projPath)]
                if args.ignore_unclassified:
                    command.append('--ignore_unclassified')
            else:
                command = ['{}/utils/sqmreads2tables.py'.format(SQMpath), '{}'.format(projPath), '{}/results/tables'.format(projPath)]
            if args.trusted_functions:
                command.append('--trusted-functions')
            command.append('--force-overwrite')
            call(command)
        else:
            print('The "{}/results/tables" directory is already present. Skipping...'.format(projPath))

        
        samples = parse_table('{}/results/tables/{}.superkingdom.allfilter.abund.tsv'.format(projPath, projName), all_superkingdom)
        sampleNames.extend(samples)

        parse_table('{}/results/tables/{}.phylum.allfilter.abund.tsv'.format(projPath, projName), all_phylum)
        parse_table('{}/results/tables/{}.class.allfilter.abund.tsv'.format(projPath, projName), all_class)
        parse_table('{}/results/tables/{}.order.allfilter.abund.tsv'.format(projPath, projName), all_order)
        parse_table('{}/results/tables/{}.family.allfilter.abund.tsv'.format(projPath, projName), all_family)
        parse_table('{}/results/tables/{}.genus.allfilter.abund.tsv'.format(projPath, projName), all_genus)
        parse_table('{}/results/tables/{}.species.allfilter.abund.tsv'.format(projPath, projName), all_species)

        parse_table('{}/results/tables/{}.superkingdom.prokfilter.abund.tsv'.format(projPath, projName), prok_superkingdom)
        parse_table('{}/results/tables/{}.phylum.prokfilter.abund.tsv'.format(projPath, projName), prok_phylum)
        parse_table('{}/results/tables/{}.class.prokfilter.abund.tsv'.format(projPath, projName), prok_class)
        parse_table('{}/results/tables/{}.order.prokfilter.abund.tsv'.format(projPath, projName), prok_order)
        parse_table('{}/results/tables/{}.family.prokfilter.abund.tsv'.format(projPath, projName), prok_family)
        parse_table('{}/results/tables/{}.genus.prokfilter.abund.tsv'.format(projPath, projName), prok_genus)
        parse_table('{}/results/tables/{}.species.prokfilter.abund.tsv'.format(projPath, projName), prok_species)

        parse_table('{}/results/tables/{}.KO.abund.tsv'.format(projPath, projName), KOabund)
        if not args.sqmreads:
            parse_table('{}/results/tables/{}.KO.copyNumber.tsv'.format(projPath, projName), KOcopy)
            parse_table('{}/results/tables/{}.KO.tpm.tsv'.format(projPath, projName), KOtpm)

        parse_table('{}/results/tables/{}.COG.abund.tsv'.format(projPath, projName), COGabund)
        if not args.sqmreads:
            parse_table('{}/results/tables/{}.COG.copyNumber.tsv'.format(projPath, projName), COGcopy)
            parse_table('{}/results/tables/{}.COG.tpm.tsv'.format(projPath, projName), COGtpm)

        if not args.sqmreads:
            parse_table('{}/results/tables/{}.PFAM.abund.tsv'.format(projPath, projName), PFAMabund)
            parse_table('{}/results/tables/{}.PFAM.copyNumber.tsv'.format(projPath, projName), PFAMcopy)
            parse_table('{}/results/tables/{}.PFAM.tpm.tsv'.format(projPath, projName), PFAMtpm)


    prefix = '{}/{}.'.format(args.output_dir, args.output_prefix)

    write_feature_dict(sampleNames, all_superkingdom, prefix + 'superkingdom.allfilter.abund.tsv')
    write_feature_dict(sampleNames, all_phylum, prefix + 'phylum.allfilter.abund.tsv')
    write_feature_dict(sampleNames, all_class, prefix + 'class.allfilter.abund.tsv')
    write_feature_dict(sampleNames, all_order, prefix + 'order.allfilter.abund.tsv')
    write_feature_dict(sampleNames, all_family, prefix + 'family.allfilter.abund.tsv')
    write_feature_dict(sampleNames, all_genus, prefix + 'genus.allfilter.abund.tsv')
    write_feature_dict(sampleNames, all_species, prefix + 'species.allfilter.abund.tsv')

    write_feature_dict(sampleNames, prok_superkingdom, prefix + 'superkingdom.prokfilter.abund.tsv')
    write_feature_dict(sampleNames, prok_phylum, prefix + 'phylum.prokfilter.abund.tsv')
    write_feature_dict(sampleNames, prok_class, prefix + 'class.prokfilter.abund.tsv')
    write_feature_dict(sampleNames, prok_order, prefix + 'order.prokfilter.abund.tsv')
    write_feature_dict(sampleNames, prok_family, prefix + 'family.prokfilter.abund.tsv')
    write_feature_dict(sampleNames, prok_genus, prefix + 'genus.prokfilter.abund.tsv')
    write_feature_dict(sampleNames, prok_species, prefix + 'species.prokfilter.abund.tsv')

    write_feature_dict(sampleNames, KOabund, prefix + 'KO.abund.tsv')
    if not args.sqmreads: 
        write_feature_dict(sampleNames, KOcopy, prefix + 'KO.copyNumber.tsv')
        write_feature_dict(sampleNames, KOtpm, prefix + 'KO.tpm.tsv')

    write_feature_dict(sampleNames, COGabund, prefix + 'COG.abund.tsv')
    if not args.sqmreads:
        write_feature_dict(sampleNames, COGcopy, prefix + 'COG.copyNumber.tsv')
        write_feature_dict(sampleNames, COGtpm, prefix + 'COG.tpm.tsv')

    if not args.sqmreads:
        write_feature_dict(sampleNames, PFAMabund, prefix + 'PFAM.abund.tsv')
        write_feature_dict(sampleNames, PFAMcopy, prefix + 'PFAM.copyNumber.tsv')
        write_feature_dict(sampleNames, PFAMtpm, prefix + 'PFAM.tpm.tsv')



def parse_table(path, targetDict):
    """
    Inserts a set of samples from a table in a dictionary.
    The dictionary is modified in place.
    Returns a list with the names of the samples.
    """
    with open(path) as infile:
        samples = infile.readline().strip().split('\t')
        for sample in samples:
            if sample in targetDict:
                raise Exception('Error where parsing table in "{}". Sample "{}" appears more than once in your input tables.'.format(path, sample))
            targetDict[sample] = {}
        for line in infile:
            line = line.strip().split('\t')
            feature = line[0]
            for sample, value in zip(samples, line[1:]):
                targetDict[sample][feature] = value
        return samples


def write_feature_dict(sampleNames, featureDict, outName):
    df = DataFrame.from_dict(featureDict).fillna(0)
    df = df.sort_index()
    df = df[sampleNames]
    df.to_csv(outName, sep='\t')



def parse_args():
    parser = argparse.ArgumentParser(description='Aggregate SqueezeMeta results into tables', epilog='Fernando Puente-Sánchez (CNB) 2019\n')
    parser.add_argument('project_paths', type=str, nargs='*', help='Base paths of the SqueezeMeta projects to combine')
    parser.add_argument('-f', '--paths_file', type=str, help='File containing the base paths of the SqueezeMeta projects to combine (one per line)')
    parser.add_argument('-o', '--output-dir', type=str, default='combined', help='Output directory')
    parser.add_argument('-p', '--output-prefix', type=str, default='combined', help='Prefix for output files')
    parser.add_argument('--trusted-functions', action='store_true', help='Include only ORFs with highly trusted KEGG and COG assignments in aggregated functional tables')
    parser.add_argument('--ignore-unclassified', action='store_true', help='Ignore ORFs without assigned functions in TPM calculation')
    parser.add_argument('--sqmreads', action='store_true', help='Projects were generated using sqm_reads.pl')
    parser.add_argument('--force-overwrite', action='store_true', help='Write results even if the output directory already exists')

    return parser.parse_args()


if __name__ == '__main__':
    main(parse_args())
